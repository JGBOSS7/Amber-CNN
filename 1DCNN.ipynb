{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0ff7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "topol = open('topol.top','r')\n",
    "lines = topol.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0347eed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4926 9597 21744 30183 42557\n"
     ]
    }
   ],
   "source": [
    "bonds_begin = 0\n",
    "pairs_begin = 0\n",
    "angles_begin = 0\n",
    "dihed_begin1 = 0\n",
    "dihed_begin2 = 0\n",
    "for i in range(len(lines)):\n",
    "    if lines[i] == '[ bonds ]\\n':\n",
    "        bonds_begin = i\n",
    "    if lines[i] == '[ pairs ]\\n':\n",
    "        pairs_begin = i\n",
    "    if lines[i] == '[ angles ]\\n':\n",
    "        angles_begin = i\n",
    "    if lines[i] == '[ dihedrals ]\\n':\n",
    "        if dihed_begin1 == 0:\n",
    "            dihed_begin1 = i\n",
    "        else:\n",
    "            dihed_begin2 = i\n",
    "print(bonds_begin, pairs_begin, angles_begin, dihed_begin1, dihed_begin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f85a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds = []\n",
    "for i in range(bonds_begin+2, pairs_begin):\n",
    "    if lines[i] == '\\n':\n",
    "        break\n",
    "    else:\n",
    "        nums = lines[i].split()[:-1]\n",
    "        nums = [int(i) for i in nums]\n",
    "        bonds.append(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b240f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for i in range(pairs_begin+2, angles_begin):\n",
    "    if lines[i] == '\\n':\n",
    "        break\n",
    "    else:\n",
    "        nums = lines[i].split()[:-1]\n",
    "        nums = [int(i) for i in nums]\n",
    "        pairs.append(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83cfa030",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = []\n",
    "for i in range(angles_begin+2, dihed_begin1):\n",
    "    if lines[i] == '\\n':\n",
    "        break\n",
    "    else:\n",
    "        nums = lines[i].split()[:-1]\n",
    "        nums = [int(i) for i in nums]\n",
    "        angles.append(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "469a9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diheds = []\n",
    "for i in range(dihed_begin1+2, dihed_begin2):\n",
    "    if lines[i] == '\\n':\n",
    "        break\n",
    "    else:\n",
    "        nums = lines[i].split()[:-1]\n",
    "        nums = [int(i) for i in nums]\n",
    "        diheds.append(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8360c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diheds_common = []\n",
    "for i in range(dihed_begin2+2, len(lines)):\n",
    "    if lines[i] == '\\n':\n",
    "        break\n",
    "    else:\n",
    "        nums = lines[i].split()[:-1]\n",
    "        nums = [int(i) for i in nums]\n",
    "        diheds_common.append(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d055ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/jai/mambaforge/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from MDAnalysis import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ee4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIG PARAMETERS ###\n",
    "rel_atoms = ['N','C','CA','CB','O'] ### atoms to consider from data\n",
    "universe = Universe('active.gro', 'active.xtc') ### files to take as reference\n",
    "batch_size = 5 ### batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7532df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_atoms = universe.atoms.names\n",
    "rel_atoms_universe = []\n",
    "rel_atoms_universe_names = []\n",
    "for i in range(len(all_atoms)):\n",
    "    if(all_atoms[i] in rel_atoms):\n",
    "        rel_atoms_universe.append(i+1)\n",
    "        rel_atoms_universe_names.append(all_atoms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de5e5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coords = []\n",
    "for frame in universe.trajectory:\n",
    "    req_atoms_in_frame = []\n",
    "    all_atoms_in_frame = universe.atoms.positions\n",
    "    for j in rel_atoms_universe:\n",
    "        req_atoms_in_frame.append(all_atoms_in_frame[j])\n",
    "    all_coords.append(req_atoms_in_frame)\n",
    "all_coords = np.array(all_coords)\n",
    "all_coords = np.transpose(all_coords, (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdf6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x_train, transform=True):\n",
    "        self.transform = transform\n",
    "        self.x = torch.from_numpy(x_train)\n",
    "        self.x = self.x.to(torch.float32)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f56ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test = train_test_split(all_coords, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1161d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset(x_train)\n",
    "test_dataset = dataset(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f256fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c5bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55943a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_bonds = []\n",
    "rel_pairs = []\n",
    "rel_angles = []\n",
    "rel_diheds = []\n",
    "rel_diheds_common = []\n",
    "for bond in bonds:\n",
    "    if all(item in rel_atoms_universe for item in bond):\n",
    "        rel_bonds.append(bond)\n",
    "for pair in pairs:\n",
    "    if all(item in rel_atoms_universe for item in pair):\n",
    "        rel_pairs.append(pair)\n",
    "for angle in angles:\n",
    "    if all(item in rel_atoms_universe for item in angle):\n",
    "        rel_angles.append(angle)\n",
    "for dihed in diheds:\n",
    "    if all(item in rel_atoms_universe for item in dihed):\n",
    "        rel_diheds.append(dihed)\n",
    "for dihed_common in diheds_common:\n",
    "    if all(item in rel_atoms_universe for item in dihed_common):\n",
    "        rel_diheds_common.append(dihed_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf259a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C - N', 'CA - CB', 'C - O', 'CA - C', 'N - CA', 'CB - CA']\n"
     ]
    }
   ],
   "source": [
    "named_bonds = []\n",
    "for bond in rel_bonds:\n",
    "    atom1 = rel_atoms_universe.index(bond[0])\n",
    "    atom2 = rel_atoms_universe.index(bond[1])\n",
    "    named_bonds.append(rel_atoms_universe_names[atom1] + ' - ' + rel_atoms_universe_names[atom2])\n",
    "unique_named_bonds = list(set(named_bonds))\n",
    "print(unique_named_bonds)\n",
    "k_b_vals = [469.0, 469.0, 337.0, 570.0, 469.0, 490.0]\n",
    "r_vals = [1.4040, 1.4040, 1.4490, 1.2290, 1.4090, 1.3350]\n",
    "def bonded_loss(frames, rel_atoms_universe, rel_bonds, named_bonds, unique_named_bonds):\n",
    "    pots = []\n",
    "    for frame in frames:\n",
    "        coords = torch.transpose(frame, 0, 1)\n",
    "        dists = []\n",
    "        for bond in rel_bonds:\n",
    "            coord1 = coords[rel_atoms_universe.index(bond[0])]\n",
    "            coord2 = coords[rel_atoms_universe.index(bond[1])]\n",
    "            dist = torch.norm(coord1-coord2)\n",
    "            dists.append(dist)\n",
    "        pot = 0\n",
    "        for i in range(len(named_bonds)):\n",
    "            ind = unique_named_bonds.index(named_bonds[i])\n",
    "            k = k_b_vals[ind]\n",
    "            r = r_vals[ind]\n",
    "            pot = pot + (k * (r - dists[i]) ** 2)\n",
    "        pots.append(pot.cpu().detach())\n",
    "    pots = np.array(pots)\n",
    "    return pots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6f2837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1460569.6, 1446766.1, 1435318.2, 1452793.8, 1455059.9],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonded_loss(data, rel_atoms_universe, rel_bonds, named_bonds, unique_named_bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "635d5273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA - C - O', 'N - CA - CB', 'O - C - N', 'C - N - CA', 'CB - CA - C', 'N - CA - C', 'CA - C - N']\n"
     ]
    }
   ],
   "source": [
    "named_angles = []\n",
    "for angle in rel_angles:\n",
    "    atom1 = rel_atoms_universe.index(angle[0])\n",
    "    atom2 = rel_atoms_universe.index(angle[1])\n",
    "    atom3 = rel_atoms_universe.index(angle[2])\n",
    "    named_angles.append(rel_atoms_universe_names[atom1] + ' - ' + rel_atoms_universe_names[atom2] \\\n",
    "                        + ' - ' + rel_atoms_universe_names[atom3])\n",
    "unique_named_angles = list(set(named_angles))\n",
    "print(unique_named_angles)\n",
    "k_theta_vals = [70.0, 70.0, 63.0, 50.0, 63.0, 80.0, 80.0]\n",
    "theta_vals = [123.50, 116.60, 110.10, 121.90, 110.10, 122.90, 120.40]\n",
    "def theta_loss(frames, rel_atoms_universe, rel_angles, named_angles, unique_named_angles):\n",
    "    pots = []\n",
    "    for frame in frames:\n",
    "        coords = torch.transpose(frame, 0, 1)\n",
    "        angles = []\n",
    "        for angle in rel_angles:\n",
    "            coord1 = coords[rel_atoms_universe.index(angle[0])]\n",
    "            coord2 = coords[rel_atoms_universe.index(angle[1])]\n",
    "            coord3 = coords[rel_atoms_universe.index(angle[2])]\n",
    "            vec1 = coord1 - coord2\n",
    "            vec2 = coord3 - coord2\n",
    "            dot_product = torch.dot(vec1, vec2)\n",
    "            norm_vec1 = torch.norm(vec1)\n",
    "            norm_vec2 = torch.norm(vec2)\n",
    "            angle_radians = torch.acos(dot_product / (norm_vec1 * norm_vec2))\n",
    "            angles.append(angle_radians)\n",
    "        pot = 0\n",
    "        for i in range(len(named_angles)):\n",
    "            ind = unique_named_angles.index(named_angles[i])\n",
    "            k = k_theta_vals[ind]\n",
    "            theta = theta_vals[ind] * (np.pi / 180)\n",
    "            pot = pot + (k * (theta - angles[i]) ** 2)\n",
    "        pots.append(pot.cpu().detach())\n",
    "    pots = np.array(pots)\n",
    "    return pots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af346030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([160574.52, 158661.33, 157004.88, 159576.44, 160001.36],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_loss(data, rel_atoms_universe, rel_angles, named_angles, unique_named_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8925279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O - C - N - CA', 'CA - C - N - CA', 'N - CA - C - O', 'CB - CA - C - N', 'C - N - CA - CB', 'C - N - CA - C', 'N - CA - C - N', 'CB - CA - C - O']\n"
     ]
    }
   ],
   "source": [
    "named_diheds = []\n",
    "for dihed in rel_diheds:\n",
    "    atom1 = rel_atoms_universe.index(dihed[0])\n",
    "    atom2 = rel_atoms_universe.index(dihed[1])\n",
    "    atom3 = rel_atoms_universe.index(dihed[2])\n",
    "    atom4 = rel_atoms_universe.index(dihed[3])\n",
    "    named_diheds.append(rel_atoms_universe_names[atom1] + ' - ' + rel_atoms_universe_names[atom2] \\\n",
    "                        + ' - ' + rel_atoms_universe_names[atom3] + ' - ' + rel_atoms_universe_names[atom4])\n",
    "unique_named_diheds = list(set(named_diheds))\n",
    "print(unique_named_diheds)\n",
    "v_vals = [10.00, [0.00, 0.55, 1.58, 0.45], 0.00, 14.50, 14.50, [0.00, 0.42, 0.27, 0.00], 10.00, 14.50]\n",
    "n_vals = [2.0, [4.0, 3.0, 2.0, 1.0], 2.0, 2.0, 2.0, [4.0, 3.0, 2.0, 1.0], 2.0, 2.0]\n",
    "gamma_vals = [180.0, [0.0, 180.0, 180.0, 180.0], 0.0, 180.0, 180.0, [0.0, 0.0, 0.0, 0.0], 180.0, 180.0]\n",
    "divider_vals = [4.0, [1.0, 1.0, 1.0, 1.0], 6.0, 4.0, 4.0, [1.0, 1.0, 1.0, 1.0], 4.0, 4.0]\n",
    "def dihed_loss(frames, rel_atoms_universe, rel_diheds, named_diheds, unique_named_diheds):\n",
    "    pots = []\n",
    "    for frame in frames:\n",
    "        coords = torch.transpose(frame, 0, 1)\n",
    "        diheds = []\n",
    "        for dihed in rel_diheds:\n",
    "            coord1 = coords[rel_atoms_universe.index(dihed[0])]\n",
    "            coord2 = coords[rel_atoms_universe.index(dihed[1])]\n",
    "            coord3 = coords[rel_atoms_universe.index(dihed[2])]\n",
    "            coord4 = coords[rel_atoms_universe.index(dihed[3])]\n",
    "            vec1 = coord1 - coord2\n",
    "            vec2 = coord3 - coord2\n",
    "            vec3 = coord4 - coord3\n",
    "            cross_product1 = torch.cross(vec1, vec2)\n",
    "            cross_product2 = torch.cross(vec2, vec3)\n",
    "            numerator = torch.dot(cross_product1, cross_product2)\n",
    "            denominator = torch.norm(cross_product1) * torch.norm(cross_product2)\n",
    "            dihedral_angle_radians = torch.atan2(numerator, denominator)\n",
    "            diheds.append(dihedral_angle_radians)\n",
    "        pot = 0\n",
    "        for i in range(len(named_diheds)):\n",
    "            ind = unique_named_diheds.index(named_diheds[i])\n",
    "            v = v_vals[ind]\n",
    "            n = n_vals[ind]\n",
    "            gamma = gamma_vals[ind]\n",
    "            if isinstance(v, list):\n",
    "                for j in range(len(v)):\n",
    "                    pot = pot + (v[j] * (1 + torch.cos((n[j] * diheds[i]) - (gamma[j] * (np.pi / 180)))))\n",
    "            else:\n",
    "                pot = pot + (v * (1 + torch.cos((n * diheds[i]) - (gamma * (np.pi / 180)))))\n",
    "        pots.append(pot.cpu().detach())\n",
    "    pots = np.array(pots)\n",
    "    return pots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a41a8981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12288.709, 12211.571, 12146.79 , 12203.72 , 12486.601],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dihed_loss(data, rel_atoms_universe, rel_diheds, named_diheds, unique_named_diheds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d17bc656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA - N - C - O']\n"
     ]
    }
   ],
   "source": [
    "named_diheds_common = []\n",
    "for dihed_common in rel_diheds_common:\n",
    "    atom1 = rel_atoms_universe.index(dihed_common[0])\n",
    "    atom2 = rel_atoms_universe.index(dihed_common[1])\n",
    "    atom3 = rel_atoms_universe.index(dihed_common[2])\n",
    "    atom4 = rel_atoms_universe.index(dihed_common[3])\n",
    "    named_diheds_common.append(rel_atoms_universe_names[atom1] + ' - ' + rel_atoms_universe_names[atom2] \\\n",
    "                        + ' - ' + rel_atoms_universe_names[atom3] + ' - ' + rel_atoms_universe_names[atom4])\n",
    "unique_named_diheds_common = list(set(named_diheds_common))\n",
    "print(unique_named_diheds_common)\n",
    "v_vals_common = [10.50]\n",
    "n_vals_common = [2.0]\n",
    "gamma_vals_common = [180.0]\n",
    "divider_vals_common = [1.0]\n",
    "def dihed_loss_common(frames, rel_atoms_universe, rel_diheds_common, named_diheds_common, unique_named_diheds_common):\n",
    "    pots = []\n",
    "    for frame in frames:\n",
    "        coords = torch.transpose(frame, 0, 1)\n",
    "        diheds_common = []\n",
    "        for dihed_common in rel_diheds_common:\n",
    "            coord1 = coords[rel_atoms_universe.index(dihed_common[0])]\n",
    "            coord2 = coords[rel_atoms_universe.index(dihed_common[1])]\n",
    "            coord3 = coords[rel_atoms_universe.index(dihed_common[2])]\n",
    "            coord4 = coords[rel_atoms_universe.index(dihed_common[3])]\n",
    "            vec1 = coord1 - coord2\n",
    "            vec2 = coord3 - coord2\n",
    "            vec3 = coord4 - coord3\n",
    "            cross_product1 = torch.cross(vec1, vec2)\n",
    "            cross_product2 = torch.cross(vec2, vec3)\n",
    "            numerator = torch.dot(cross_product1, cross_product2)\n",
    "            denominator = torch.norm(cross_product1) * torch.norm(cross_product2)\n",
    "            dihedral_angle_radians = torch.atan2(numerator, denominator)\n",
    "            diheds_common.append(dihedral_angle_radians)\n",
    "        pot = 0\n",
    "        for i in range(len(named_diheds_common)):\n",
    "            ind = unique_named_diheds_common.index(named_diheds_common[i])\n",
    "            v = v_vals_common[ind]\n",
    "            n = n_vals_common[ind]\n",
    "            gamma = gamma_vals_common[ind]\n",
    "            if isinstance(v, list):\n",
    "                for j in range(len(v)):\n",
    "                    pot = pot + (v[j] * (1 + torch.cos((n[j] * diheds_common[i]) - (gamma[j] * (np.pi / 180)))))\n",
    "            else:\n",
    "                pot = pot + (v * (1 + torch.cos((n * diheds_common[i]) - (gamma * (np.pi / 180)))))\n",
    "        pots.append(pot.cpu().detach())\n",
    "    pots = np.array(pots)\n",
    "    return pots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8dc9e5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2798.3562, 2781.8381, 2762.107 , 2788.1335, 2761.492 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dihed_loss_common(data, rel_atoms_universe, rel_diheds_common, named_diheds_common, unique_named_diheds_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c9d30b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O - CA', 'CB - N', 'CA - CA', 'C - C', 'CB - O', 'N - O', 'N - N', 'C - CB']\n"
     ]
    }
   ],
   "source": [
    "named_pairs = []\n",
    "numbered_pairs = []\n",
    "for pair in rel_pairs:\n",
    "    atom1 = rel_atoms_universe.index(pair[0])\n",
    "    atom2 = rel_atoms_universe.index(pair[1])\n",
    "    named_pairs.append(rel_atoms_universe_names[atom1] + ' - ' + rel_atoms_universe_names[atom2])\n",
    "    numbered_pairs.append((atom1, atom2))\n",
    "unique_named_pairs = list(set(named_pairs))\n",
    "print(unique_named_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7703d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_min = {\n",
    "    'N': '1.8240',\n",
    "    'C': '1.9080',\n",
    "    'CA': '1.9080',\n",
    "    'CB': '1.9080',\n",
    "    'O': '1.6612'\n",
    "}\n",
    "epsilon = {\n",
    "    'N': '0.1700',\n",
    "    'C': '0.0860',\n",
    "    'CA': '0.0860',\n",
    "    'CB': '0.0860',\n",
    "    'O': '0.2100'\n",
    "}\n",
    "ep_ij_matrix = np.full((len(rel_atoms_universe_names), len(rel_atoms_universe_names)), -1, dtype=float)\n",
    "R_ij_matrix = np.full((len(rel_atoms_universe_names), len(rel_atoms_universe_names)), -1, dtype=float)\n",
    "\n",
    "for i in range(0,len(rel_atoms_universe_names)-1):\n",
    "    for j in range(i+1,len(rel_atoms_universe_names)):\n",
    "        ep_ij_matrix[i][j] = np.sqrt(float(epsilon[rel_atoms_universe_names[i]]) * float(epsilon[rel_atoms_universe_names[j]]))\n",
    "for i in range(0,len(rel_atoms_universe_names)-1):\n",
    "    for j in range(i+1,len(rel_atoms_universe_names)):\n",
    "        R_ij_matrix[i][j] = (float(R_min[rel_atoms_universe_names[i]]) + float(R_min[rel_atoms_universe_names[j]])) / 2\n",
    "\n",
    "A_ij_matrix = ep_ij_matrix * np.power(R_ij_matrix, 12)\n",
    "B_ij_matrix = 2 * ep_ij_matrix * np.power(R_ij_matrix, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9f09e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonbonded_loss(frames, A_ij_matrix, B_ij_matrix, numbered_pairs):\n",
    "    pots = []\n",
    "    for frame in frames:\n",
    "        coords = torch.transpose(frame, 0, 1)\n",
    "        nums = coords.shape[0]\n",
    "        coords_a = coords.unsqueeze(1).repeat(1, nums, 1)\n",
    "        coords_b = coords.unsqueeze(0).repeat(nums, 1, 1)\n",
    "        pairwise_distances = torch.sqrt(torch.sum((coords_a - coords_b)**2, dim=2))\n",
    "        pairwise_distances = pairwise_distances.cpu().detach().numpy()\n",
    "        mask = pairwise_distances > 10.0\n",
    "        preserve_mask = np.zeros_like(pairwise_distances, dtype=bool)\n",
    "        for index in numbered_pairs:\n",
    "            preserve_mask[index] = True\n",
    "        pairwise_distances[np.logical_and(mask, ~preserve_mask)] = -1.0\n",
    "        #print(pairwise_distances.shape)\n",
    "        positive_mask = pairwise_distances > 0.0\n",
    "        first_term = np.zeros_like(A_ij_matrix, dtype=float)\n",
    "        first_term[positive_mask] = A_ij_matrix[positive_mask] / np.power(pairwise_distances[positive_mask], 12)\n",
    "        second_matrix = np.zeros_like(B_ij_matrix, dtype=float)\n",
    "        second_matrix[positive_mask] = B_ij_matrix[positive_mask] / np.power(pairwise_distances[positive_mask], 6)\n",
    "        LJ_pot = np.sum(first_term) + np.sum(second_matrix)\n",
    "        pots.append(LJ_pot)\n",
    "    pots = np.array(pots)\n",
    "    return pots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dad9b65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38389.45395794, 38373.12558173, 38211.27649282, 38123.60479163,\n",
       "       38262.30872786])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonbonded_loss(data, A_ij_matrix, B_ij_matrix, numbered_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11ecc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_Loss, self).__init__()\n",
    "    \n",
    "    def forward(self, predicted, target, rel_atoms_universe, rel_bonds, named_bonds, unique_named_bonds,\\\n",
    "               rel_angles, named_angles, unique_named_angles, rel_diheds, named_diheds, unique_named_diheds,\\\n",
    "               rel_diheds_common, named_diheds_common, unique_named_diheds_common, A_ij_matrix, B_ij_matrix, numbered_pairs):\n",
    "        mse_losses = []\n",
    "        for i in range(target.shape[0]):\n",
    "            out = predicted[i]\n",
    "            inp = target[i]\n",
    "            #print(out, inp)\n",
    "            MSE_Loss = mseloss(out, inp)\n",
    "            mse_losses.append(MSE_Loss)\n",
    "        amber_loss = bonded_loss(predicted, rel_atoms_universe, rel_bonds, named_bonds, unique_named_bonds)\\\n",
    "                    + theta_loss(predicted, rel_atoms_universe, rel_angles, named_angles, unique_named_angles) + \\\n",
    "                    + dihed_loss(predicted, rel_atoms_universe, rel_diheds, named_diheds, unique_named_diheds) + \\\n",
    "                    + dihed_loss_common(predicted, rel_atoms_universe, rel_diheds_common, named_diheds_common, unique_named_diheds_common) +\\\n",
    "                    + nonbonded_loss(predicted, A_ij_matrix, B_ij_matrix, numbered_pairs)\n",
    "        final_losses = []\n",
    "        for i in range(target.shape[0]):\n",
    "            beta_parm = mse_losses[i] / (10 * amber_loss[i])\n",
    "            final_loss = mse_losses[i] + (beta_parm * amber_loss[i])\n",
    "            final_losses.append(final_loss)\n",
    "        final_losses = torch.tensor(final_losses)\n",
    "        final_loss = torch.mean(final_losses)\n",
    "        return final_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1da95af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, f):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [nn.Conv1d(f, f, 3, stride=1, padding=1, bias=False),\n",
    "                      nn.BatchNorm1d(f),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.Conv1d(f, f, 3, stride=1, padding=1, bias=False),\n",
    "                      nn.BatchNorm1d(f)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "        # return torch.relu(x + self.conv_block(x))       #earlier runs were with 'return x + self.conv_block(x)' but not an issue (really?)\n",
    "\n",
    "\n",
    "class To2D(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(To2D, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = torch.nn.functional.adaptive_avg_pool2d(x, output_size=(2, 1))\n",
    "        z = torch.sigmoid(z)\n",
    "        return z\n",
    "\n",
    "\n",
    "class From2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(From2D, self).__init__()\n",
    "        self.f = nn.Linear(2, 22*1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 2)\n",
    "        #print(x.shape)\n",
    "        x = self.f(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), 1, 22)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    '''\n",
    "    This is the autoencoder used in our `Ramaswamy 2021 paper <https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.011052>`_.\n",
    "    It is largely superseded by :func:`molearn.models.foldingnet.AutoEncoder`.\n",
    "    '''\n",
    "    def __init__(self, kernel=4, stride=2, padding=1, init_z=32, latent_z=1, depth=4, m=1.5, r=0, droprate=None):\n",
    "        '''\n",
    "        :param int init_z: number of channels in first layer\n",
    "        :param int latent_z: number of latent space dimensions\n",
    "        :param int depth: number of layers\n",
    "        :param float m: scaling factor, dictating number of channels in subsequent layers\n",
    "        :param int r: number of residual blocks between layers\n",
    "        :param float droprate: dropout rate\n",
    "        '''\n",
    "\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # encoder block\n",
    "        eb = nn.ModuleList()\n",
    "        eb.append(nn.Conv1d(3, init_z, kernel, stride, padding, bias=False))\n",
    "        eb.append(nn.BatchNorm1d(init_z))\n",
    "        if droprate is not None:\n",
    "            eb.append(nn.Dropout(p=droprate))\n",
    "        eb.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        for i in range(depth):\n",
    "            eb.append(nn.Conv1d(int(init_z*m**i), int(init_z*m**(i+1)), kernel, stride, padding, bias=False))\n",
    "            eb.append(nn.BatchNorm1d(int(init_z*m**(i+1))))\n",
    "            if droprate is not None:\n",
    "                eb.append(nn.Dropout(p=droprate))\n",
    "            eb.append(nn.ReLU(inplace=True))\n",
    "            for j in range(r):\n",
    "                eb.append(ResidualBlock(int(init_z*m**(i+1))))\n",
    "        eb.append(nn.Conv1d(int(init_z*m**depth), latent_z, kernel, stride, padding, bias=False))\n",
    "        eb.append(To2D())\n",
    "        self.encoder = eb\n",
    "\n",
    "\n",
    "        # decoder block\n",
    "        db = nn.ModuleList()\n",
    "        db.append(From2D())\n",
    "        db.append(nn.ConvTranspose1d(latent_z, int(init_z*m**(depth)), kernel, stride, padding, bias=False))\n",
    "        db.append(nn.BatchNorm1d(int(init_z*m**(depth))))\n",
    "        if droprate is not None:\n",
    "            db.append(nn.Dropout(p=droprate))\n",
    "        db.append(nn.ReLU(inplace=True))\n",
    "        for i in reversed(range(depth)):\n",
    "            if int(init_z*m**i) == 72:\n",
    "                db.append(nn.ConvTranspose1d(int(init_z*m**(i+1)), int(init_z*m**i), kernel, stride, padding, bias=False, output_padding=1))\n",
    "            else:\n",
    "                db.append(nn.ConvTranspose1d(int(init_z*m**(i+1)), int(init_z*m**i), kernel, stride, padding, bias=False))\n",
    "            db.append(nn.BatchNorm1d(int(init_z*m**i)))\n",
    "            if droprate is not None:\n",
    "                db.append(nn.Dropout(p=droprate))\n",
    "            db.append(nn.ReLU(inplace=True))\n",
    "            for j in range(r):\n",
    "                db.append(ResidualBlock(int(init_z*m**i)))\n",
    "        db.append(nn.ConvTranspose1d(int(init_z*m**(i)), 3, kernel, stride, padding, output_padding=1))\n",
    "        self.decoder = db\n",
    "\n",
    "    def encode(self, x):\n",
    "        for m in self.encoder:\n",
    "            x = m(x)\n",
    "            #print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        for m in self.decoder:\n",
    "            x = m(x)\n",
    "            #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8bf173a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent shape: torch.Size([5, 2, 1])\n",
      "Output shape: torch.Size([5, 3, 1417])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor (batch size, input channels, sequence length)\n",
    "#input_tensor = torch.randn(15, 3, 100)\n",
    "\n",
    "input_tensor = torch.randn(5, 3, 1417)\n",
    "\n",
    "# Instantiate the model\n",
    "model = Autoencoder()\n",
    "\n",
    "# Encode\n",
    "latent = model.encode(input_tensor)\n",
    "\n",
    "# Print the latent layer shape\n",
    "print(\"Latent shape:\", latent.shape)\n",
    "\n",
    "#Decode\n",
    "output = model.decode(latent)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "732577a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "mseloss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "494ce4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0/80, Loss: 2493.357421875\n",
      "epoch 0 : 1/80, Loss: 2446.70361328125\n",
      "epoch 0 : 2/80, Loss: 2435.744140625\n",
      "epoch 0 : 3/80, Loss: 2519.859619140625\n",
      "epoch 0 : 4/80, Loss: 2381.942138671875\n",
      "epoch 0 : 5/80, Loss: 2527.589111328125\n",
      "epoch 0 : 6/80, Loss: 2531.6513671875\n",
      "epoch 0 : 7/80, Loss: 2613.510498046875\n",
      "epoch 0 : 8/80, Loss: 2404.72119140625\n",
      "epoch 0 : 9/80, Loss: 2532.39111328125\n",
      "epoch 0 : 10/80, Loss: 2665.461669921875\n",
      "epoch 0 : 11/80, Loss: 2591.81494140625\n",
      "epoch 0 : 12/80, Loss: 2405.281982421875\n",
      "epoch 0 : 13/80, Loss: 2685.15234375\n",
      "epoch 0 : 14/80, Loss: 2535.997314453125\n",
      "epoch 0 : 15/80, Loss: 2430.01904296875\n",
      "epoch 0 : 16/80, Loss: 2449.22412109375\n",
      "epoch 0 : 17/80, Loss: 2519.736083984375\n",
      "epoch 0 : 18/80, Loss: 2378.699951171875\n",
      "epoch 0 : 19/80, Loss: 2447.099609375\n",
      "epoch 0 : 20/80, Loss: 2479.66162109375\n",
      "epoch 0 : 21/80, Loss: 2481.616455078125\n",
      "epoch 0 : 22/80, Loss: 2432.03369140625\n",
      "epoch 0 : 23/80, Loss: 2421.657470703125\n",
      "epoch 0 : 24/80, Loss: 2557.41455078125\n",
      "epoch 0 : 25/80, Loss: 2447.318359375\n",
      "epoch 0 : 26/80, Loss: 2482.51318359375\n",
      "epoch 0 : 27/80, Loss: 2465.43017578125\n",
      "epoch 0 : 28/80, Loss: 2507.670654296875\n",
      "epoch 0 : 29/80, Loss: 2540.38525390625\n",
      "epoch 0 : 30/80, Loss: 2376.033935546875\n",
      "epoch 0 : 31/80, Loss: 2425.13427734375\n",
      "epoch 0 : 32/80, Loss: 2455.12841796875\n",
      "epoch 0 : 33/80, Loss: 2510.09326171875\n",
      "epoch 0 : 34/80, Loss: 2384.7421875\n",
      "epoch 0 : 35/80, Loss: 2400.6875\n",
      "epoch 0 : 36/80, Loss: 2414.85498046875\n",
      "epoch 0 : 37/80, Loss: 2337.12841796875\n",
      "epoch 0 : 38/80, Loss: 2391.3271484375\n",
      "epoch 0 : 39/80, Loss: 2452.094482421875\n",
      "epoch 0 : 40/80, Loss: 2503.00244140625\n",
      "epoch 0 : 41/80, Loss: 2455.11669921875\n",
      "epoch 0 : 42/80, Loss: 2446.025634765625\n",
      "epoch 0 : 43/80, Loss: 2421.11962890625\n",
      "epoch 0 : 44/80, Loss: 2523.52490234375\n",
      "epoch 0 : 45/80, Loss: 2438.552001953125\n",
      "epoch 0 : 46/80, Loss: 2739.748291015625\n",
      "epoch 0 : 47/80, Loss: 2476.011474609375\n",
      "epoch 0 : 48/80, Loss: 2476.837158203125\n",
      "epoch 0 : 49/80, Loss: 2347.67822265625\n",
      "epoch 0 : 50/80, Loss: 2501.90283203125\n",
      "epoch 0 : 51/80, Loss: 2407.60205078125\n",
      "epoch 0 : 52/80, Loss: 2538.2041015625\n",
      "epoch 0 : 53/80, Loss: 2443.920166015625\n",
      "epoch 0 : 54/80, Loss: 2404.014892578125\n",
      "epoch 0 : 55/80, Loss: 2563.572265625\n",
      "epoch 0 : 56/80, Loss: 2575.1669921875\n",
      "epoch 0 : 57/80, Loss: 2646.54931640625\n",
      "epoch 0 : 58/80, Loss: 2414.08251953125\n",
      "epoch 0 : 59/80, Loss: 2352.454833984375\n",
      "epoch 0 : 60/80, Loss: 2455.84716796875\n",
      "epoch 0 : 61/80, Loss: 2397.818359375\n",
      "epoch 0 : 62/80, Loss: 2550.059326171875\n",
      "epoch 0 : 63/80, Loss: 2444.3564453125\n",
      "epoch 0 : 64/80, Loss: 2577.140625\n",
      "epoch 0 : 65/80, Loss: 2483.85693359375\n",
      "epoch 0 : 66/80, Loss: 2509.984619140625\n",
      "epoch 0 : 67/80, Loss: 2420.56640625\n",
      "epoch 0 : 68/80, Loss: 2393.39013671875\n",
      "epoch 0 : 69/80, Loss: 2476.660400390625\n",
      "epoch 0 : 70/80, Loss: 2508.624267578125\n",
      "epoch 0 : 71/80, Loss: 2432.169189453125\n",
      "epoch 0 : 72/80, Loss: 2526.641845703125\n",
      "epoch 0 : 73/80, Loss: 2484.435791015625\n",
      "epoch 0 : 74/80, Loss: 2369.895751953125\n",
      "epoch 0 : 75/80, Loss: 2434.467264823125\n",
      "epoch 0 : 76/80, Loss: 2471.04931640625\n",
      "epoch 0 : 77/80, Loss: 2440.9248046875\n",
      "epoch 0 : 78/80, Loss: 2598.35009765625\n",
      "epoch 0 : 79/80, Loss: 2366.44775390625\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "outputs = []\n",
    "losses = []\n",
    "model.train()\n",
    "epoch_losses = []\n",
    "test_losses = []\n",
    "#encodings = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    test_loss = []\n",
    "    #test_enc = np.array([]).reshape(0,latent_dim)\n",
    "    for i, image in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # print(image.dtype)\n",
    "        # break4\n",
    "        # image = image.to(torch.float32)\n",
    "        image = image.to(device)\n",
    "        latent = model.encode(image)\n",
    "        reconstructed = model.decode(latent)\n",
    "        #break\n",
    "        criterion = Custom_Loss()\n",
    "        loss = criterion(reconstructed, image, rel_atoms_universe, rel_bonds, named_bonds, unique_named_bonds,\\\n",
    "               rel_angles, named_angles, unique_named_angles, rel_diheds, named_diheds, unique_named_diheds,\\\n",
    "               rel_diheds_common, named_diheds_common, unique_named_diheds_common, A_ij_matrix, B_ij_matrix, numbered_pairs)\n",
    "        loss = torch.autograd.Variable(loss, requires_grad=True)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "        #train_enc = train_enc + encoded_inp\n",
    "        #outputs.append((epochs, image, reconstructed))\n",
    "        print(\"epoch {} : {}/{}, Loss: {}\".format(epoch, i, len(train_loader), loss.item()))\n",
    "    for i, image in enumerate(test_loader):\n",
    "        # print(image.dtype)\n",
    "        # break4\n",
    "        # image = image.to(torch.float32)\n",
    "        image = image.to(device)\n",
    "        latent = model.encode(image)\n",
    "        reconstructed = model.decode(latent)\n",
    "        \n",
    "        criterion = Custom_Loss()\n",
    "        loss = criterion(reconstructed, image, rel_atoms_universe, rel_bonds, named_bonds, unique_named_bonds,\\\n",
    "               rel_angles, named_angles, unique_named_angles, rel_diheds, named_diheds, unique_named_diheds,\\\n",
    "               rel_diheds_common, named_diheds_common, unique_named_diheds_common, A_ij_matrix, B_ij_matrix, numbered_pairs)\n",
    "        loss = torch.autograd.Variable(loss, requires_grad=True)\n",
    "\n",
    "        test_loss.append(loss.item())\n",
    "        #if test_enc.size==0:\n",
    "            #test_enc = np.vstack([test_enc,encoded_inp.cpu().detach().numpy()])\n",
    "        #else:\n",
    "            #test_enc = np.concatenate((test_enc,encoded_inp.cpu().detach().numpy()), axis=0)\n",
    "        #print(encoded_inp.cpu().detach().numpy())\n",
    "        #outputs.append((epochs, image, reconstructed))\n",
    "        #print(\"epoch {} : {}/{}, Loss: {}\".format(epoch, i, len(test_loader), loss.item()))\n",
    "    epoch_losses.append(np.average(epoch_loss))\n",
    "    test_losses.append(np.average(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256eec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b5177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
